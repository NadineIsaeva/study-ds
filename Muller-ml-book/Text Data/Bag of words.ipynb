{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train = load_files('aclImdb/train')\n",
    "reviews_test = load_files('aclImdb/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "25000\n",
      "b'Words can\\'t describe how bad this movie is. I can\\'t explain it by writing only. You have too see it for yourself to get at grip of how horrible a movie really can be. Not that I recommend you to do that. There are so many clich\\xc3\\xa9s, mistakes (and all other negative things you can imagine) here that will just make you cry. To start with the technical first, there are a LOT of mistakes regarding the airplane. I won\\'t list them here, but just mention the coloring of the plane. They didn\\'t even manage to show an airliner in the colors of a fictional airline, but instead used a 747 painted in the original Boeing livery. Very bad. The plot is stupid and has been done many times before, only much, much better. There are so many ridiculous moments here that i lost count of it really early. Also, I was on the bad guys\\' side all the time in the movie, because the good guys were so stupid. \"Executive Decision\" should without a doubt be you\\'re choice over this one, even the \"Turbulence\"-movies are better. In fact, every other movie in the world is better than this one.'\n"
     ]
    }
   ],
   "source": [
    "text_train, y_train = reviews_train.data, reviews_train.target\n",
    "print(type(text_train))\n",
    "print(len(text_train))\n",
    "print(text_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pos/neg reviews: [12500 12500]\n"
     ]
    }
   ],
   "source": [
    "text_train = [doc.replace(b'<br />', b' ') for doc in text_train]\n",
    "print('Number of pos/neg reviews: {}'.format(np.bincount(y_train)))\n",
    "# Balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n",
      "Number of pos/neg reviews (test): [12500 12500]\n"
     ]
    }
   ],
   "source": [
    "text_test, y_test = reviews_test.data, reviews_test.target\n",
    "print(len(text_test))\n",
    "print('Number of pos/neg reviews (test): {}'.format(np.bincount(y_test)))\n",
    "text_test = [doc.replace(b'<br />', b' ') for doc in text_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of words - representation strategy, discards structure in text.\n",
    "\n",
    "Count how often each word appears in each text in corpus (dataset)\n",
    "\n",
    "1. Tokenize\n",
    "2. Build vocabulary\n",
    "3. Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 13\n",
      "Vocab content: {'the': 9, 'fool': 3, 'doth': 2, 'think': 10, 'he': 4, 'is': 6, 'wise': 12, 'but': 1, 'man': 8, 'knows': 7, 'himself': 5, 'to': 11, 'be': 0}\n"
     ]
    }
   ],
   "source": [
    "# Example bag of words\n",
    "bards_words =[\"The fool doth think he is wise,\",\n",
    "              \"but the wise man knows himself to be a fool\"]\n",
    "vect = CountVectorizer()\n",
    "vect.fit(bards_words) # tokenize and build vocabulary\n",
    "print('Vocabulary size: {}'.format(len(vect.vocabulary_)))\n",
    "print('Vocab content: {}'.format(vect.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1],\n",
       "       [1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words = vect.transform(bards_words) # encode to bag of words representation\n",
    "bag_of_words.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<25000x74849 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 3431196 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "# Bag of words imdb\n",
    "vect = CountVectorizer()\n",
    "vect.fit(text_train) # tokenize and build vocab\n",
    "X_train = vect.transform(text_train) # encode to bag of words representation\n",
    "print(repr(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 74849\n",
      "\n",
      "First 20 features: ['00', '000', '0000000000001', '00001', '00015', '000s', '001', '003830', '006', '007', '0079', '0080', '0083', '0093638', '00am', '00pm', '00s', '01', '01pm', '02']\n",
      "\n",
      "20010 to 20030 features: ['dratted', 'draub', 'draught', 'draughts', 'draughtswoman', 'draw', 'drawback', 'drawbacks', 'drawer', 'drawers', 'drawing', 'drawings', 'drawl', 'drawled', 'drawling', 'drawn', 'draws', 'draza', 'dre', 'drea']\n",
      "\n",
      "Every 2000th feature: ['00', 'aesir', 'aquarian', 'barking', 'blustering', 'bÃªte', 'chicanery', 'condensing', 'cunning', 'detox', 'draper', 'enshrined', 'favorit', 'freezer', 'goldman', 'hasan', 'huitieme', 'intelligible', 'kantrowitz', 'lawful', 'maars', 'megalunged', 'mostey', 'norrland', 'padilla', 'pincher', 'promisingly', 'receptionist', 'rivals', 'schnaas', 'shunning', 'sparse', 'subset', 'temptations', 'treatises', 'unproven', 'walkman', 'xylophonist']\n"
     ]
    }
   ],
   "source": [
    "feature_names = vect.get_feature_names()\n",
    "print('Number of features: {}\\n'.format(len(feature_names)))\n",
    "print('First 20 features: {}\\n'.format(feature_names[:20]))\n",
    "print('20010 to 20030 features: {}\\n'.format(feature_names[20010:20030]))\n",
    "print('Every 2000th feature: {}'.format(feature_names[::2000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CV accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(LogisticRegression(solver='lbfgs', max_iter=100000), X_train, y_train, cv=5)\n",
    "print('Mean CV accuracy: {:.2f}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.87\n"
     ]
    }
   ],
   "source": [
    "X_test = vect.transform(text_test)\n",
    "lr = LogisticRegression(solver='lbfgs', max_iter=100000).fit(X_train, y_train)\n",
    "print('Test score: {:.2f}'.format(lr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV score: 0.89\n",
      "Best parameters: {'C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# Tune C\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "grid = GridSearchCV(LogisticRegression(solver='lbfgs', max_iter=100000), param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "print('Best CV score: {:.2f}'.format(grid.best_score_))\n",
    "print('Best parameters: {}'.format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.88\n"
     ]
    }
   ],
   "source": [
    "X_test = vect.transform(text_test)\n",
    "print('Test score: {:.2f}'.format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<25000x27271 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 3354014 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "# Set minimum number of documents token needs to appear in\n",
    "vect = CountVectorizer(min_df=5)\n",
    "\n",
    "# Tokenize and build vocab\n",
    "vect.fit(text_train)\n",
    "\n",
    "# Encode\n",
    "X_train = vect.transform(text_train)\n",
    "print(repr(X_train))\n",
    "\n",
    "# Reduced number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 27271\n",
      "\n",
      "First 20 features: ['00', '000', '007', '00s', '01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '100', '1000', '100th', '101', '102', '103']\n",
      "\n",
      "20010 to 20030 features: ['repentance', 'repercussions', 'repertoire', 'repetition', 'repetitions', 'repetitious', 'repetitive', 'rephrase', 'replace', 'replaced', 'replacement', 'replaces', 'replacing', 'replay', 'replayable', 'replayed', 'replaying', 'replays', 'replete', 'replica']\n",
      "\n",
      "Every 1000th feature: ['00', 'alternatively', 'baked', 'bothersome', 'centipede', 'complicity', 'cutlery', 'disgraceful', 'elton', 'fatal', 'gaining', 'hamburgers', 'ideals', 'ivory', 'leering', 'martin', 'moxy', 'opportunist', 'picasso', 'prudish', 'repartee', 'sas', 'silvers', 'standup', 'talkative', 'trend', 'verisimilitude', 'wreaking']\n"
     ]
    }
   ],
   "source": [
    "feature_names = vect.get_feature_names()\n",
    "print('Number of features: {}\\n'.format(len(feature_names)))\n",
    "print('First 20 features: {}\\n'.format(feature_names[:20]))\n",
    "print('20010 to 20030 features: {}\\n'.format(feature_names[20010:20030]))\n",
    "print('Every 1000th feature: {}'.format(feature_names[::1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV score: 0.89\n",
      "Best parameters: {'C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(LogisticRegression(solver='lbfgs', max_iter=100000), param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "print('Best CV score: {:.2f}'.format(grid.best_score_))\n",
    "print('Best parameters: {}'.format(grid.best_params_))\n",
    "\n",
    "# Less number of features didn't imrpove accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
